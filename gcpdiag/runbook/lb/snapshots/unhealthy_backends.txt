backend_service_name=web-backend-service,project_id=gcpdiag-lb2-aaaa

lb/unhealthy-backends: Load Balancer Unhealthy Backends Analyzer.

  This runbook helps investigate why backends in a load balancer are unhealthy.
  It confirms and summarizes the current health status of the backends, aiding
  in identifying any unhealthy instances.

  Key Investigation Areas:

  - Firewalls:
      - Verifies if firewall rules are properly configured to allow health check
      traffic.
  - Port Configuration:
      - Validates if the health check and serving ports are configured
      correctly, ensuring they are not mismatched.
  - Logging:
      - Checks if health check logging is enabled to aid in troubleshooting.
  - Health Check Logs (if enabled):
      - Analyzes the latest health check logs to identify the specific reasons
      for backend unhealthiness:
          - Timeouts: Identifies if the backend is timing out and provides
          potential causes and remediation steps.
          - Unhealthy: Indicates that the backend is reachable but doesn't meet
          the health check's criteria. It provides guidance on the expected
          health check behavior and suggests configuration checks.
          - Unknown: Explains the potential reasons for the "UNKNOWN" health
          state and suggests actions like adjusting timeouts or checking for
          Google Cloud outages.
  - Past Health Check Success:
      - Checks if the health check has worked successfully in the past to
      determine if the issue is recent or ongoing.
  
[START]: Checks the health of a specified load balancer's backends.
[INFO]: name: web-backend-service, region: global

   - gcpdiag-lb2-aaaa/web-backend-service                                 [FAIL]
     [REASON]
     Unhealthy backends were found in backend service web-backend-service in scope global.
     Group https://www.googleapis.com/compute/v1/projects/gcpdiag-lb2-aaaa/zones/us-east1-b/instanceGroups/lb-backend-example has 2/2 unhealthy backends


[GATEWAY]: Check if health check logging is enabled.

   - gcpdiag-lb2-aaaa/http-basic-check                                    [OK]
     [REASON]
     Health check logging is enabled

[GATEWAY]: Look for the latest health check logs and based on that decide what to do next.
[AUTOMATED STEP]: Analyzes logs with the detailed health check state TIMEOUT

   - gcpdiag-lb2-aaaa/web-backend-service                                 [UNCERTAIN]
     [REASON]
     Health check logs show the detailed health state "TIMEOUT".
     The backend might be timing out because:
     1. The application is overloaded and taking too long to respond.
     2. The backend service or health check timeout is too low.
     3. Connection to the endpoint cannot be established - the backend instance has crashed or is otherwise unresponsive.
     The following responses were received from your backends: "HTTP response: , Error: Timeout waiting for connect"

     [REMEDIATION]
     1. Make sure that the backend service timeout (current value: 30s) and health check timeout (current value: 5s) are appropriately configured to accommodate your application's expected response time.
     2. Investigate your application's configuration to ensure it is correctly handling health check probe requests. Your health check is using HTTP protocol, and it is set to: 
     - send a prober requests to the / path on port 80 
     - expect a response with an HTTP 200 (OK) status code
     3. Check if firewall rules or iptables configurations are not blocking the health check probes from reaching the backend instances, resulting in timeouts.

[AUTOMATED STEP]: Checks if the health check has worked successfully in the past.

   - gcpdiag-lb2-aaaa/web-backend-service                                 [UNCERTAIN]
     [REASON]
     https://www.googleapis.com/compute/v1/projects/gcpdiag-lb2-aaaa/zones/us-east1-b/instanceGroups/lb-backend-example: Backends transitioned to an unhealthy state at 2024-08-13T09:20:22.666336211Z


     [REMEDIATION]
     Check the logs and monitoring metrics for those instances, focusing on the given timeframes to see if there were any errors, crashes, or resource exhaustion issues that coincide with the unhealthy transition. You can also inspect any application-specific logs for errors or warnings around the timestamp.

[AUTOMATED STEP]: Checks if health check sends probe requests to the different port than serving port.

   - gcpdiag-lb2-aaaa/web-backend-service                                 [UNCERTAIN]
     [REASON]
     The load balancer is performing health checks on port 88. We detected that within some backend instance groups, this is different than the port that the load balancer is using for serving traffic. The backend service is configured to use the "http" port, which is translated to a port number based on the "http" port mapping within each backend instance group.

     Affected backends:
     projects/gcpdiag-lb2-aaaa/zones/us-east1-b/instanceGroups/lb-backend-example - port name "http" translates to port 80

     This configuration can be problematic unless you have configured the load balancer to use a different port for health checks purposefully.

[AUTOMATED STEP]: Checks if firewall rules are configured correctly.

   - gcpdiag-lb2-aaaa/web-backend-service                                 [FAIL]
     [REASON]
     Health check firewall is not configured
     The health checks are currently failing due to a misconfigured firewall. This is preventing Google Cloud probers from connecting to your backends, causing the load balancer to consider them unhealthy.

     [REMEDIATION]
     Update your firewall rules to allow inbound traffic from the Google Cloud health check IP ranges (found at https://cloud.google.com/load-balancing/docs/health-check-concepts#ip-ranges) to your backends.

[COMPOSITE STEP]: Checks if the VM performance is degraded.

    In this step one unhealthy instance from each group is analyzed - disks,
    memory and cpu utilization are being checked.
    
[AUTOMATED STEP]: Verify VM memory utilization is within optimal levels.

   - gcpdiag-lb2-aaaa/vm-pn3l                                             [FAIL]
     [REASON]
     Memory utilization on this VM has reached levels that may compromise its VM application performance.

     [REMEDIATION]
     Elevated memory usage can result in slow or unresponsive or termimated applications.
     Consider enhancing the VM's memory capacity by changing to a machine type with more memory.
     Guidance on stopping and changing the machine type can be found here:
     - Changing machine type:
     https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     For deeper analysis of memory issues:

     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#memory_utilization

     Or connect via the Serial Console if SSH is not available to mitigate the issue.
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console

[AUTOMATED STEP]: Verify there are any memory related errors in Serial logs

   - gcpdiag-lb2-aaaa/vm-pn3l                                             [UNCERTAIN]
     [REASON]
     We did not find any Memory related errors in Serial console logs

     [REMEDIATION]
     You may check if VM is facing high memory utilisation from GuestOS side using `free -m`
     or `cat /proc/meminfo` commands.

[AUTOMATED STEP]: Verify VM's Boot disk space utilization is within optimal levels.

   - gcpdiag-lb2-aaaa/vm-pn3l                                             [FAIL]
     [REASON]
     Disk utilization on this VM's boot disk is critically high,
     potentially affecting application performance.

     [REMEDIATION]
     To mitigate high disk usage, consider expanding the VM's boot disk capacity.
     This action can help avoid performance issues and ensure smoother SSH connections.
     Follow the guide to increase disk size:
     https://cloud.google.com/compute/docs/disks/resize-persistent-disk#increase_the_size_of_a_disk

[AUTOMATED STEP]: Verify VM CPU utilization is within optimal levels

   - gcpdiag-lb2-aaaa/vm-pn3l                                             [FAIL]
     [REASON]
     CPU utilization on this VM has surpassed recommended operational levels,
     which may affect its performance and SSH connectivity.

     [REMEDIATION]
     Excessive CPU usage can lead to performance bottlenecks. Consider resizing the VM to a more
     powerful machine type with higher CPU capabilities.
     Detailed instructions for resizing and restarting VMs are available here:
     - Stopping a VM: https://cloud.google.com/compute/docs/instances/stop-start-instance
     - Resizing a VM: https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#access_vm_observability_metrics
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#process_utilization

     Alternatively, you can connect via serial console if SSH is unvailable to stop offending processes
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console.

[END]: Finalize unhealthy backends diagnostics.


backend_service_name=backend-service-2,project_id=gcpdiag-lb2-aaaa,region=europe-west4

lb/unhealthy-backends: Load Balancer Unhealthy Backends Analyzer.

  This runbook helps investigate why backends in a load balancer are unhealthy.
  It confirms and summarizes the current health status of the backends, aiding
  in identifying any unhealthy instances.

  Key Investigation Areas:

  - Firewalls:
      - Verifies if firewall rules are properly configured to allow health check
      traffic.
  - Port Configuration:
      - Validates if the health check and serving ports are configured
      correctly, ensuring they are not mismatched.
  - Logging:
      - Checks if health check logging is enabled to aid in troubleshooting.
  - Health Check Logs (if enabled):
      - Analyzes the latest health check logs to identify the specific reasons
      for backend unhealthiness:
          - Timeouts: Identifies if the backend is timing out and provides
          potential causes and remediation steps.
          - Unhealthy: Indicates that the backend is reachable but doesn't meet
          the health check's criteria. It provides guidance on the expected
          health check behavior and suggests configuration checks.
          - Unknown: Explains the potential reasons for the "UNKNOWN" health
          state and suggests actions like adjusting timeouts or checking for
          Google Cloud outages.
  - Past Health Check Success:
      - Checks if the health check has worked successfully in the past to
      determine if the issue is recent or ongoing.
  
[START]: Checks the health of a specified load balancer's backends.
[INFO]: name: backend-service-2, region: europe-west4

   - gcpdiag-lb2-aaaa/backend-service-2                                   [FAIL]
     [REASON]
     Unhealthy backends were found in backend service backend-service-2 in scope europe-west4.
     Group https://www.googleapis.com/compute/v1/projects/gcpdiag-lb2-aaaa/zones/europe-west4-b/networkEndpointGroups/neg1 has 1/1 unhealthy backends


[GATEWAY]: Check if health check logging is enabled.

   - gcpdiag-lb2-aaaa/tcp-basic-check-2                                   [OK]
     [REASON]
     Health check logging is enabled

[GATEWAY]: Look for the latest health check logs and based on that decide what to do next.
[AUTOMATED STEP]: Analyzes logs with the detailed health check state TIMEOUT

   - gcpdiag-lb2-aaaa/backend-service-2                                   [UNCERTAIN]
     [REASON]
     Health check logs show the detailed health state "TIMEOUT".
     The backend might be timing out because:
     1. The application is overloaded and taking too long to respond.
     2. The backend service or health check timeout is too low.
     3. Connection to the endpoint cannot be established - the backend instance has crashed or is otherwise unresponsive.
     The following responses were received from your backends: "HTTP response: , Error: Timeout waiting for connect"

     [REMEDIATION]
     1. Make sure that the backend service timeout (current value: 30s) and health check timeout (current value: 5s) are appropriately configured to accommodate your application's expected response time.
     2. Investigate your application's configuration to ensure it is correctly handling health check probe requests. Your health check is using TCP protocol, and it is set to: 
     - send a prober requests on port 80
     - expect a successful TCP handshake
     3. Check if firewall rules or iptables configurations are not blocking the health check probes from reaching the backend instances, resulting in timeouts.

[AUTOMATED STEP]: Checks if the health check has worked successfully in the past.

   - gcpdiag-lb2-aaaa/backend-service-2                                   [UNCERTAIN]
     [REASON]
     https://www.googleapis.com/compute/v1/projects/gcpdiag-lb2-aaaa/zones/europe-west4-b/networkEndpointGroups/neg1: Backends transitioned to an unhealthy state at 2024-08-13T09:20:22.666336211Z


     [REMEDIATION]
     Check the logs and monitoring metrics for those instances, focusing on the given timeframes to see if there were any errors, crashes, or resource exhaustion issues that coincide with the unhealthy transition. You can also inspect any application-specific logs for errors or warnings around the timestamp.

[AUTOMATED STEP]: Checks if health check sends probe requests to the different port than serving port.

   - gcpdiag-lb2-aaaa/backend-service-2                                   [OK]
     [REASON]
     The load balancer is performing health checks on the same port that it is using for serving traffic. This is the standard configuration.

[AUTOMATED STEP]: Checks if firewall rules are configured correctly.

   - gcpdiag-lb2-aaaa/backend-service-2                                   [OK]
     [REASON]
     Firewalls are correctly configured and are not blocking the health check probes.

[COMPOSITE STEP]: Checks if the VM performance is degraded.

    In this step one unhealthy instance from each group is analyzed - disks,
    memory and cpu utilization are being checked.
    
[AUTOMATED STEP]: Verify VM memory utilization is within optimal levels.

   - gcpdiag-lb2-aaaa/neg-vm                                              [FAIL]
     [REASON]
     Memory utilization on this VM has reached levels that may compromise its VM application performance.

     [REMEDIATION]
     Elevated memory usage can result in slow or unresponsive or termimated applications.
     Consider enhancing the VM's memory capacity by changing to a machine type with more memory.
     Guidance on stopping and changing the machine type can be found here:
     - Changing machine type:
     https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     For deeper analysis of memory issues:

     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#memory_utilization

     Or connect via the Serial Console if SSH is not available to mitigate the issue.
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console

[AUTOMATED STEP]: Verify there are any memory related errors in Serial logs

   - gcpdiag-lb2-aaaa/neg-vm                                              [UNCERTAIN]
     [REASON]
     We did not find any Memory related errors in Serial console logs

     [REMEDIATION]
     You may check if VM is facing high memory utilisation from GuestOS side using `free -m`
     or `cat /proc/meminfo` commands.

[AUTOMATED STEP]: Verify VM's Boot disk space utilization is within optimal levels.

   - gcpdiag-lb2-aaaa/neg-vm                                              [FAIL]
     [REASON]
     Disk utilization on this VM's boot disk is critically high,
     potentially affecting application performance.

     [REMEDIATION]
     To mitigate high disk usage, consider expanding the VM's boot disk capacity.
     This action can help avoid performance issues and ensure smoother SSH connections.
     Follow the guide to increase disk size:
     https://cloud.google.com/compute/docs/disks/resize-persistent-disk#increase_the_size_of_a_disk

[AUTOMATED STEP]: Verify VM CPU utilization is within optimal levels

   - gcpdiag-lb2-aaaa/neg-vm                                              [FAIL]
     [REASON]
     CPU utilization on this VM has surpassed recommended operational levels,
     which may affect its performance and SSH connectivity.

     [REMEDIATION]
     Excessive CPU usage can lead to performance bottlenecks. Consider resizing the VM to a more
     powerful machine type with higher CPU capabilities.
     Detailed instructions for resizing and restarting VMs are available here:
     - Stopping a VM: https://cloud.google.com/compute/docs/instances/stop-start-instance
     - Resizing a VM: https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#access_vm_observability_metrics
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#process_utilization

     Alternatively, you can connect via serial console if SSH is unvailable to stop offending processes
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console.

[END]: Finalize unhealthy backends diagnostics.


