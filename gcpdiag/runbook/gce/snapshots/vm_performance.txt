name=faulty-linux-ssh,project_id=gcpdiag-gce-vm-performance,zone=europe-west2-a

gce/vm-performance:  Google Compute Engine VM performance checks

  This runbook is designed to assist you in investigating and understanding the underlying reasons
  behind the performance issues of your Google Compute Engine VMs within Google Cloud Platform.

  Key Investigation Areas:

    - High CPU utilisation
    - CPU Over-commitment for E2 or Sole-Tenant VMs
    - High Memory utilisation
    - Disk space high utilisation
    - High Disk IOPS utilisation
    - High Disk Throughput utilisation
    - Disk Health check
    - Disk IO latency check
    - Disk Slowness check
    - Check for Live Migrations
    - Usual Error checks in Serial console logs
  
[START]: Verify GCE VM is in a running state.
[AUTOMATED STEP]: Verify GCE VM is in a running state.
[AUTOMATED STEP]: Verify VM CPU utilization is within optimal levels

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     CPU utilization on this VM has surpassed recommended operational levels,
     which may affect its performance and SSH connectivity.

     [REMEDIATION]
     Excessive CPU usage can lead to performance bottlenecks. Consider resizing the VM to a more
     powerful machine type with higher CPU capabilities.
     Detailed instructions for resizing and restarting VMs are available here:
     - Stopping a VM: https://cloud.google.com/compute/docs/instances/stop-start-instance
     - Resizing a VM: https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#access_vm_observability_metrics
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#process_utilization

     Alternatively, you can connect via serial console if SSH is unvailable to stop offending processes
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console.

[AUTOMATED STEP]: Checking if CPU is overcommited

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     CPU for the VM faulty-linux-ssh is over committed beyond acceptable limits: 0 ms/s
[AUTOMATED STEP]: Verify VM memory utilization is within optimal levels.

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     Memory utilization on this VM has reached levels that may compromise its VM application performance.

     [REMEDIATION]
     Elevated memory usage can result in slow or unresponsive or termimated applications.
     Consider enhancing the VM's memory capacity by changing to a machine type with more memory.
     Guidance on stopping and changing the machine type can be found here:
     - Changing machine type:
     https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     For deeper analysis of memory issues:

     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#memory_utilization

     Or connect via the Serial Console if SSH is not available to mitigate the issue.
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console

[AUTOMATED STEP]: Verify there are any memory related errors in Serial logs

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [UNCERTAIN]
     [REASON]
     We did not find any Memory related errors in Serial console logs

     [REMEDIATION]
     You may check if VM is facing high memory utilisation from GuestOS side using `free -m`
     or `cat /proc/meminfo` commands.

[AUTOMATED STEP]: Verify instance disks are healthy

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     You might experience slower/poor performance with your disk 'persistent-disk-0' due to an
     ongoing issue with our Compute Engine or Persistent Disk infrastructure. We're working
     to resolve this as quickly as possible.

     [REMEDIATION]
     To better understand the situation with your Compute Engine or Persistent Disks,
     could you please take a look at the Google Cloud Status page:

     https://status.cloud.google.com

     This page provides real-time updates on the health of Google Cloud services.

     Additionally, it may be helpful to check the Service Health dashboard in your
     Google Cloud Console for any reported incidents:

     https://console.cloud.google.com/servicehealth/incidents

     If you don't find any information about an ongoing issue related to your concern,
     please don't hesitate to reach out to Google Cloud Support by creating a support case.
     They'll be happy to investigate further and assist you.

[AUTOMATED STEP]: Verify VM's Boot disk space utilization is within optimal levels.

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     Disk utilization on this VM's boot disk is critically high,
     potentially affecting application performance.

     [REMEDIATION]
     To mitigate high disk usage, consider expanding the VM's boot disk capacity.
     This action can help avoid performance issues and ensure smoother SSH connections.
     Follow the guide to increase disk size:
     https://cloud.google.com/compute/docs/disks/resize-persistent-disk#increase_the_size_of_a_disk

[AUTOMATED STEP]: Verify any slow Disk operations related errors in Serial console logs

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [UNCERTAIN]
     [REASON]
     We did not find any slow Disk operations related errors in Serial console logs

     [REMEDIATION]


[AUTOMATED STEP]: Verify any Filesystem corruption related errors in Serial console logs

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     Possibe filesystem corruption detected.

     The patterns we looked for :
     'Corruption of in-memory data detected. Shutting down filesystem',
     'Corruption of in-memory data detected', 'warning: mounting fs with errors',
     'Failed to mount /',
     'A stop job is running for Security \.\.\..* Service ',
     'I/O Error Detected. Shutting down filesystem',
     'metadata I/O error in'

     [REMEDIATION]
     To fix the filesystem correuption, you may use gce-rescue[1] available in cloud shell to
     rescue faulty VMs or go via manual mathod[2] to repair the filesystem.

     More articles you may refer:
     https://access.redhat.com/solutions/1750923


     [1]
     https://github.com/GoogleCloudPlatform/gce-rescue

     [2]
     https://cloud.google.com/compute/docs/troubleshooting/rescue-vm ,
     https://www.youtube.com/watch?v=oD6IFpjEtEw

[AUTOMATED STEP]: Verify Instance's Disk Avg IO Latency is within optimal limits

   - gcpdiag-gce-vm-performance/faulty-linux-ssh                          [FAIL]
     [REASON]
     The performance of the disk 'faulty-linux-ssh' is currently degraded due to high
     IO latency exceeding optimal thresholds. This may result in slower read/write
     speeds and overall reduced performance.

     [REMEDIATION]
     Disk I/O latency is the time it takes for a read or write operation to complete on a
     disk.
     High disk I/O latency can significantly impact the performance of your applications
     and workloads running on the instance, leading to slow response times, increased
     processing time, and overall sluggishness.

     Potential Bottlenecks -
     - Disk Type: To optimize disk performance, ensure your disk type is appropriate
     for your workload and provides acceptable latency for your system architecture.
     Choosing the right disk type can significantly impact performance.
     https://cloud.google.com/compute/docs/disks

     - Workload: The nature of your workload also influences latency. Workloads with
     many small, random I/O operations will generally have higher latency than those
     with sequential I/O

     Optimize Disk Usage:
     - Reduce I/O Operations: Optimize your applications and database queries to minimize
     the number of disk I/O operations.
     - Increase I/O Request Size: Larger I/O requests can be more efficient than many small
     ones. Consider adjusting your application or database settings to increase the I/O
     request size.
     - Caching: Implement caching mechanisms to reduce the need to access the disk for
     frequently used data.

     Choose the Right Disk Type with lesser IO Latency - https://cloud.google.com/compute/docs/disks

     You may also look into Optimizing persistent disk performance. -
     https://cloud.google.com/compute/docs/disks/optimizing-pd-performance

     Please don't hesitate to reach out to Google Cloud Support if issue is not resolved.

[AUTOMATED STEP]: Verify live migrations happened for the instance
[INFO]: 

Live Migration Detected at 2021/11/24 16:29:21, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:34:35, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:34:37, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:34:38, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:35:08, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:35:10, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:35:22, Checking further


[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[END]: Finalize VM performance diagnostics.


name=faulty-windows-ssh,project_id=gcpdiag-gce-vm-performance,zone=europe-west2-a

gce/vm-performance:  Google Compute Engine VM performance checks

  This runbook is designed to assist you in investigating and understanding the underlying reasons
  behind the performance issues of your Google Compute Engine VMs within Google Cloud Platform.

  Key Investigation Areas:

    - High CPU utilisation
    - CPU Over-commitment for E2 or Sole-Tenant VMs
    - High Memory utilisation
    - Disk space high utilisation
    - High Disk IOPS utilisation
    - High Disk Throughput utilisation
    - Disk Health check
    - Disk IO latency check
    - Disk Slowness check
    - Check for Live Migrations
    - Usual Error checks in Serial console logs
  
[START]: Verify GCE VM is in a running state.
[AUTOMATED STEP]: Verify GCE VM is in a running state.
[AUTOMATED STEP]: Verify VM CPU utilization is within optimal levels

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [FAIL]
     [REASON]
     CPU utilization on this VM has surpassed recommended operational levels,
     which may affect its performance and SSH connectivity.

     [REMEDIATION]
     Excessive CPU usage can lead to performance bottlenecks. Consider resizing the VM to a more
     powerful machine type with higher CPU capabilities.
     Detailed instructions for resizing and restarting VMs are available here:
     - Stopping a VM: https://cloud.google.com/compute/docs/instances/stop-start-instance
     - Resizing a VM: https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#access_vm_observability_metrics
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#process_utilization

     Alternatively, you can connect via serial console if SSH is unvailable to stop offending processes
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console.

[AUTOMATED STEP]: Checking if CPU is overcommited

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [FAIL]
     [REASON]
     CPU for the VM faulty-windows-ssh is over committed beyond acceptable limits: 0 ms/s
[AUTOMATED STEP]: Verify VM memory utilization is within optimal levels.

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [FAIL]
     [REASON]
     Memory utilization on this VM has reached levels that may compromise its VM application performance.

     [REMEDIATION]
     Elevated memory usage can result in slow or unresponsive or termimated applications.
     Consider enhancing the VM's memory capacity by changing to a machine type with more memory.
     Guidance on stopping and changing the machine type can be found here:
     - Changing machine type:
     https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
     For deeper analysis of memory issues:

     Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
     https://cloud.google.com/compute/docs/instances/observe-monitor-vms#memory_utilization

     Or connect via the Serial Console if SSH is not available to mitigate the issue.
     https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console

[AUTOMATED STEP]: Verify there are any memory related errors in Serial logs

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [UNCERTAIN]
     [REASON]
     We did not find any Memory related errors in Serial console logs

     [REMEDIATION]
     You may check if VM is facing high memory utilisation from GuestOS side using `free -m`
     or `cat /proc/meminfo` commands.

[AUTOMATED STEP]: Verify instance disks are healthy

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [FAIL]
     [REASON]
     You might experience slower/poor performance with your disk 'persistent-disk-0' due to an
     ongoing issue with our Compute Engine or Persistent Disk infrastructure. We're working
     to resolve this as quickly as possible.

     [REMEDIATION]
     To better understand the situation with your Compute Engine or Persistent Disks,
     could you please take a look at the Google Cloud Status page:

     https://status.cloud.google.com

     This page provides real-time updates on the health of Google Cloud services.

     Additionally, it may be helpful to check the Service Health dashboard in your
     Google Cloud Console for any reported incidents:

     https://console.cloud.google.com/servicehealth/incidents

     If you don't find any information about an ongoing issue related to your concern,
     please don't hesitate to reach out to Google Cloud Support by creating a support case.
     They'll be happy to investigate further and assist you.

[AUTOMATED STEP]: Verify VM's Boot disk space utilization is within optimal levels.

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [FAIL]
     [REASON]
     Disk utilization on this VM's boot disk is critically high,
     potentially affecting application performance.

     [REMEDIATION]
     To mitigate high disk usage, consider expanding the VM's boot disk capacity.
     This action can help avoid performance issues and ensure smoother SSH connections.
     Follow the guide to increase disk size:
     https://cloud.google.com/compute/docs/disks/resize-persistent-disk#increase_the_size_of_a_disk

[AUTOMATED STEP]: Verify any slow Disk operations related errors in Serial console logs

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [UNCERTAIN]
     [REASON]
     We did not find any slow Disk operations related errors in Serial console logs

     [REMEDIATION]


[AUTOMATED STEP]: Verify any Filesystem corruption related errors in Serial console logs

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [UNCERTAIN]
     [REASON]
     We did not find any Filesystem corruption related errors in Serial console logs

     [REMEDIATION]


[AUTOMATED STEP]: Verify Instance's Disk Avg IO Latency is within optimal limits

   - gcpdiag-gce-vm-performance/faulty-windows-ssh                        [FAIL]
     [REASON]
     The performance of the disk 'faulty-windows-ssh' is currently degraded due to high
     IO latency exceeding optimal thresholds. This may result in slower read/write
     speeds and overall reduced performance.

     [REMEDIATION]
     Disk I/O latency is the time it takes for a read or write operation to complete on a
     disk.
     High disk I/O latency can significantly impact the performance of your applications
     and workloads running on the instance, leading to slow response times, increased
     processing time, and overall sluggishness.

     Potential Bottlenecks -
     - Disk Type: To optimize disk performance, ensure your disk type is appropriate
     for your workload and provides acceptable latency for your system architecture.
     Choosing the right disk type can significantly impact performance.
     https://cloud.google.com/compute/docs/disks

     - Workload: The nature of your workload also influences latency. Workloads with
     many small, random I/O operations will generally have higher latency than those
     with sequential I/O

     Optimize Disk Usage:
     - Reduce I/O Operations: Optimize your applications and database queries to minimize
     the number of disk I/O operations.
     - Increase I/O Request Size: Larger I/O requests can be more efficient than many small
     ones. Consider adjusting your application or database settings to increase the I/O
     request size.
     - Caching: Implement caching mechanisms to reduce the need to access the disk for
     frequently used data.

     Choose the Right Disk Type with lesser IO Latency - https://cloud.google.com/compute/docs/disks

     You may also look into Optimizing persistent disk performance. -
     https://cloud.google.com/compute/docs/disks/optimizing-pd-performance

     Please don't hesitate to reach out to Google Cloud Support if issue is not resolved.

[AUTOMATED STEP]: Verify live migrations happened for the instance
[INFO]: 

Live Migration Detected at 2021/11/24 16:29:21, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:34:35, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:34:37, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:34:38, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:35:08, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:35:10, Checking further


[INFO]: 

Live Migration Detected at 2021/11/24 16:35:22, Checking further


[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[AUTOMATED STEP]: Verify the Disk IOPS/Throughput usage is within optimal limits
[END]: Finalize VM performance diagnostics.


