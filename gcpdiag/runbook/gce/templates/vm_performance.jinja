{% block high_cpu_utilization_failure_reason %}
CPU utilization on this VM has surpassed recommended operational levels,
which may affect its performance and SSH connectivity.
{% endblock high_cpu_utilization_failure_reason %}

{% block high_cpu_utilization_failure_remediation %}
Excessive CPU usage can lead to performance bottlenecks. Consider resizing the VM to a more
powerful machine type with higher CPU capabilities.
Detailed instructions for resizing and restarting VMs are available here:
- Stopping a VM: https://cloud.google.com/compute/docs/instances/stop-start-instance
- Resizing a VM: https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
https://cloud.google.com/compute/docs/instances/observe-monitor-vms#access_vm_observability_metrics
https://cloud.google.com/compute/docs/instances/observe-monitor-vms#process_utilization

Alternatively, you can connect via serial console if SSH is unvailable to stop offending processes
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console.
{% endblock high_cpu_utilization_failure_remediation %}

{% block high_cpu_utilization_success_reason %}
This VM currently has CPU utilization within the optimal range, indicating healthy performance.
{% endblock high_cpu_utilization_success_reason %}

{% block high_disk_utilization_failure_reason %}
Disk utilization on this VM's boot disk is critically high,
potentially affecting application performance.
{% endblock high_disk_utilization_failure_reason %}

{% block high_disk_utilization_skipped_reason %}
There are no logs to examine !
{% endblock high_disk_utilization_skipped_reason %}

{% block high_disk_utilization_failure_remediation %}
To mitigate high disk usage, consider expanding the VM's boot disk capacity.
This action can help avoid performance issues and ensure smoother SSH connections.
Follow the guide to increase disk size:
https://cloud.google.com/compute/docs/disks/resize-persistent-disk#increase_the_size_of_a_disk
{% endblock high_disk_utilization_failure_remediation %}


{% block high_disk_utilization_step_message %}
Verify VM's Boot disk space utilization is within optimal levels.
{% endblock high_disk_utilization_step_message %}

{% block high_disk_utilization_success_reason %}
The VM's disk space usage is within optimal levels.
{% endblock high_disk_utilization_success_reason %}

{% block high_memory_utilization_skipped_reason %}
There are no logs to examine !
{% endblock high_memory_utilization_skipped_reason %}

{% block high_memory_utilization_failure_reason %}
Memory utilization on this VM has reached levels that may compromise its VM application performance.
{% endblock high_memory_utilization_failure_reason %}

{% block high_memory_utilization_failure_remediation %}
Elevated memory usage can result in slow or unresponsive or termimated applications.
Consider enhancing the VM's memory capacity by changing to a machine type with more memory.
Guidance on stopping and changing the machine type can be found here:
- Changing machine type:
https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
For deeper analysis of memory issues:

Additionally, use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
https://cloud.google.com/compute/docs/instances/observe-monitor-vms#memory_utilization

Or connect via the Serial Console if SSH is not available to mitigate the issue.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console
{% endblock high_memory_utilization_failure_remediation %}

{% block high_memory_utilization_success_reason %}
Memory utilization on this VM is within optimal range.
{% endblock high_memory_utilization_success_reason %}

{% block memory_error_skipped_reason %}
There are no logs to examine !
{% endblock memory_error_skipped_reason %}

{% block memory_error_step_message %}
Verify there are any memory related errors in Serial logs
{% endblock memory_error_step_message %}

{% block memory_error_success_reason %}
No memory related errors found in Serial console logs.
{% endblock memory_error_success_reason %}

{% block memory_error_failure_reason %}
We have found high disk utilisation related errors in Serial console logs.
The patterns we looked for :
'Out of memory: Kill(ed)? process', 'Kill(ed)? process',
'Memory cgroup out of memory', 'invoked oom-killer',
{% endblock memory_error_failure_reason %}

{% block memory_error_failure_remediation %}
We have found memory related errors in Serial console logs.

Please use the Compute Engine observability metrics for an in-depth analysis to pinpoint high-usage processes:
https://cloud.google.com/compute/docs/instances/observe-monitor-vms#memory_utilization

Consider enhancing the VM's memory capacity by changing to a machine type with more memory.
Guidance on stopping and changing the machine type can be found here:
- Changing machine type:
https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance#gcloud
For deeper analysis of memory issues:

Or connect via the Serial Console if SSH is not available to mitigate the issue.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console
{% endblock memory_error_failure_remediation %}

{% block memory_error_uncertain_reason %}
We did not find any Memory related errors in Serial console logs
{% endblock memory_error_uncertain_reason %}

{% block memory_error_uncertain_remediation %}
You may check if VM is facing high memory utilisation from GuestOS side using `free -m`
or `cat /proc/meminfo` commands.
{% endblock memory_error_uncertain_remediation %}


{% block high_disk_utilization_error_failure_reason %}
We have found high disk utilisation related errors in Serial console logs.
The patterns we looked for :
'No space left on device', 'No usable temporary directory found',
'A stop job is running for Security \.\.\..* Service ',
'disk is at or near capacity'
{% endblock high_disk_utilization_error_failure_reason %}

{% block high_disk_utilization_error_failure_remediation %}
To mitigate high disk usage, consider expanding the VM's boot disk capacity.
This action can help avoid performance issues and ensure accessibility of the VM.
Follow the guide to increase disk size:
https://cloud.google.com/compute/docs/disks/resize-persistent-disk#increase_the_size_of_a_disk
{% endblock high_disk_utilization_error_failure_remediation %}

{% block high_disk_utilization_error_step_message %}
Checking for high disk utilization related logs in serial console logs
{% endblock high_disk_utilization_error_step_message %}

{% block high_disk_utilization_error_success_reason %}
No high disk utilisation related errors found in Serial console logs.
{% endblock high_disk_utilization_error_success_reason %}

{% block high_disk_utilization_error_skipped_reason %}
There are no logs to examine !
{% endblock high_disk_utilization_error_skipped_reason %}

{% block high_disk_utilization_error_uncertain_reason %}
We did not find any high disk utilisation related errors in Serial console logs
{% endblock high_disk_utilization_error_uncertain_reason %}

{% block live_migrations_failure_reason %}
Live migrations detected for the VM during mentioned period.
{% endblock live_migrations_failure_reason %}

{% block live_migrations_failure_remediation %}
As remediation, you may try to simulate the migration (move the VM to another host) using
https://cloud.google.com/compute/docs/instances/simulating-host-maintenance?hl=en#testingpolicies ,
and see if issue still persists. If yes, please reach out to Google Cloud Platform Support teams via case.

Note: During live migration, VMs might experience a decrease in performance in disk,
CPU, memory, and network utilization for a short period of time.

https://cloud.google.com/compute/docs/instances/live-migration-process#how_does_the_live_migration_process_work

{% endblock live_migrations_failure_remediation %}

{% block live_migrations_step_message %}
Verify live migrations happened for the instance
{% endblock live_migrations_step_message %}

{% block live_migrations_success_reason %}
No live migrations detected for the VM during mentioned period
{% endblock live_migrations_success_reason %}

{% block live_migrations_skipped_reason %}
There are no logs to examine !
{% endblock live_migrations_skipped_reason %}


{% block slow_disk_io_step_message %}
Verify any slow Disk operations related errors in Serial console logs
{% endblock slow_disk_io_step_message %}

{% block slow_disk_io_failure_reason %}
Possibe Disk IO slowness detected.

The patterns we looked for in Serial logs:
# Linux slow read:
r'\d+:\d+:\d+:\d+: timing out command, waited \d+s',
r'end_request: I/O error, dev [a-z0-9-]+, sector \d+',
r'Buffer I/O error on device [a-z0-9-]+, logical block \d+',
r'blocked for more than \d+ seconds',

# Linux SCSI commands abort/reset (when operation to PD times out)
r'\d+:\d+:\d+:\d+:\s+\[([a-z0-9-]+)\]\s+(abort|device reset)$',
r'\d+:\d+:\d+:\d+:\s+(device reset)$',

# Linux Local SSD physical failure on console:
r'kernel: blk_update_request: I/O error, dev [a-z0-9-]+, sector \d+',

# Windows
r'The IO operation at logical block address 0x[0-9a-fA-F.]+ for Disk \d+ \(PDO name: \\Device\\.*\) was retried'
{% endblock slow_disk_io_failure_reason %}

{% block slow_disk_io_failure_remediation %}
There can be multiple reasons which can cause Slow Disk IOs:

- CPU Starvation - Small instances(with lesser CPUs) may not have enough CPU to serve all I/Os inflight.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-performance#cpu_and_memory_performance

- Network Throttling - High sent/received network traffic can cause network throttling that impacts disk operations.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-performance#network_performance

- Insufficient Machine Resources - If your machine's IOPS and throughput limts are not enought to serve your workloads,
this can also cause CPU or Disk IOPS/throughput Starvation.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-performance#storage_performance

- Application and GuestOS Operations - Unmanaged and untested application workloads can cause the high influx of IOs
to the disk and cause IO operations to be queued, causing throttling at disk and CPU levels.

To fix this issue:
- Please optmize your application workloads.
- If needed, please add more resources(CPU, Memory) to the VM.
- Please optmize your Disk performance -
https://cloud.google.com/compute/docs/disks/optimizing-pd-performance
- If needed, please change your disk type to get better Disk IOPS/throughput limits -
https://cloud.google.com/compute/docs/disks/modify-persistent-disk#disk_type

{% endblock slow_disk_io_failure_remediation %}

{% block slow_disk_io_skipped_reason %}
There are no logs to examine !
{% endblock slow_disk_io_skipped_reason %}

{% block slow_disk_io_uncertain_reason %}
We did not find any slow Disk operations related errors in Serial console logs
{% endblock slow_disk_io_uncertain_reason %}

{% block slow_disk_io_uncertain_remediation %}

{% endblock slow_disk_io_uncertain_remediation %}

{% block disk_io_usage_check_step_message %}
Verify the Disk IOPS/Throughput usage is within optimal limits
{% endblock disk_io_usage_check_step_message %}

{% block disk_io_usage_check_failure_reason %}
Disk IOPS/Throughput usage is NOT within optimal limits
{% endblock disk_io_usage_check_failure_reason %}

{% block disk_io_usage_check_failure_remediation %}
There can be multiple reasons which can cause Disk IOPS/Throughput usage to increase:

- Application and GuestOS Operations - Unmanaged and untested application workloads can cause the high influx of IOs
to the disk and cause IO operations to be queued, causing throttling at disk levels.

- CPU Starvation - Small instances(with lesser CPUs) may not have enough CPU to serve all I/Os inflight.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-performance#cpu_and_memory_performance

- Network Throttling - High sent/received network traffic can cause network throttling, that can also impacts disk
operations.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-performance#network_performance

- Insufficient Machine Resources - If your machine's IOPS and throughput limts are not enought to serve your workloads,
this can also cause CPU or Disk IOPS/throughput Starvation.
https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-performance#storage_performance

To fix this issue:
- Please optmize your application workloads.
- If needed, please add more resources(CPU, Memory) to the VM.
- Please optmize your Disk performance -
https://cloud.google.com/compute/docs/disks/optimizing-pd-performance
- If needed, please change your disk type to get better Disk IOPS/throughput limits -
https://cloud.google.com/compute/docs/disks/modify-persistent-disk#disk_type

{% endblock disk_io_usage_check_failure_remediation %}


{% block disk_health_check_step_message %}
Verify instance disks are healthy
{% endblock disk_health_check_step_message %}

{% block disk_health_check_success_reason %}
Instance disk "{disk_name}" is healthy.
{% endblock disk_health_check_success_reason %}

{% block disk_health_check_failure_reason %}
You might experience slower/poor performance with your disk '{disk_name}' due to an
ongoing issue with our Compute Engine or Persistent Disk infrastructure. We're working
to resolve this as quickly as possible.
{% endblock disk_health_check_failure_reason %}

{% block disk_health_check_failure_remediation %}
To better understand the situation with your Compute Engine or Persistent Disks,
could you please take a look at the Google Cloud Status page:

https://status.cloud.google.com

This page provides real-time updates on the health of Google Cloud services.

Additionally, it may be helpful to check the Service Health dashboard in your
Google Cloud Console for any reported incidents:

https://console.cloud.google.com/servicehealth/incidents

If you don't find any information about an ongoing issue related to your concern,
please don't hesitate to reach out to Google Cloud Support by creating a support case.
They'll be happy to investigate further and assist you.
{% endblock disk_health_check_failure_remediation %}


{% block disk_io_latency_check_step_message %}
Verify Instance's Disk Avg IO Latency is within optimal limits
{% endblock disk_io_latency_check_step_message %}

{% block disk_io_latency_check_success_reason %}
Instance disk "{disk_name}"'s IO latency is within the optimal limtis.
{% endblock disk_io_latency_check_success_reason %}

{% block disk_io_latency_check_failure_reason %}
The performance of the disk '{disk_name}' is currently degraded due to high
IO latency exceeding optimal thresholds. This may result in slower read/write
speeds and overall reduced performance.
{% endblock disk_io_latency_check_failure_reason %}

{% block disk_io_latency_check_failure_remediation %}
Disk I/O latency is the time it takes for a read or write operation to complete on a
disk.
High disk I/O latency can significantly impact the performance of your applications
and workloads running on the instance, leading to slow response times, increased
processing time, and overall sluggishness.

Potential Bottlenecks -
- Disk Type: To optimize disk performance, ensure your disk type is appropriate
for your workload and provides acceptable latency for your system architecture.
Choosing the right disk type can significantly impact performance.
https://cloud.google.com/compute/docs/disks

- Workload: The nature of your workload also influences latency. Workloads with
many small, random I/O operations will generally have higher latency than those
with sequential I/O

Optimize Disk Usage:
- Reduce I/O Operations: Optimize your applications and database queries to minimize
the number of disk I/O operations.
- Increase I/O Request Size: Larger I/O requests can be more efficient than many small
ones. Consider adjusting your application or database settings to increase the I/O
request size.
- Caching: Implement caching mechanisms to reduce the need to access the disk for
frequently used data.

Choose the Right Disk Type with lesser IO Latency - https://cloud.google.com/compute/docs/disks

You may also look into Optimizing persistent disk performance. -
https://cloud.google.com/compute/docs/disks/optimizing-pd-performance

Please don't hesitate to reach out to Google Cloud Support if issue is not resolved.
{% endblock disk_io_latency_check_failure_remediation %}
